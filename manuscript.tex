\documentclass[author-year, review, 11pt]{components/elsarticle} %review=doublespace preprint=single 5p=2 column
%%% Begin My package additions %%%%%%%%%%%%%%%%%%%
\usepackage[hyphens]{url}
\usepackage{lineno} % add 
  \linenumbers % turns line numbering on 
\bibliographystyle{elsarticle-harv}
\biboptions{sort&compress} % For natbib
\usepackage{graphicx}
\usepackage{booktabs} % book-quality tables
%% Redefines the elsarticle footer
\makeatletter
\def\ps@pprintTitle{%
 \let\@oddhead\@empty
 \let\@evenhead\@empty
 \def\@oddfoot{\it \hfill\today}%
 \let\@evenfoot\@oddfoot}
\makeatother

% A modified page layout
\textwidth 6.75in
\oddsidemargin -0.15in
\evensidemargin -0.15in
\textheight 9in
\topmargin -0.5in
%%%%%%%%%%%%%%%% end my additions to header

\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \usepackage{fontspec}
  \ifxetex
    \usepackage{xltxtra,xunicode}
  \fi
  \defaultfontfeatures{Mapping=tex-text,Scale=MatchLowercase}
  \newcommand{\euro}{â‚¬}
\fi
% use microtype if available
\IfFileExists{microtype.sty}{\usepackage{microtype}}{}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{{#1}}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{{#1}}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{{#1}}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{{#1}}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{{#1}}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{{#1}}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{{#1}}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{{#1}}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{{#1}}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{{#1}}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{{#1}}}
\newcommand{\RegionMarkerTok}[1]{{#1}}
\newcommand{\ErrorTok}[1]{\textbf{{#1}}}
\newcommand{\NormalTok}[1]{{#1}}
\usepackage{longtable}
\ifxetex
  \usepackage[setpagesize=false, % page size defined by xetex
              unicode=false, % unicode breaks when used with xetex
              xetex]{hyperref}
\else
  \usepackage[unicode=true]{hyperref}
\fi
\hypersetup{breaklinks=true,
            bookmarks=true,
            pdfauthor={},
            pdftitle={rgbif: a package for working with species occurrence data in R},
            colorlinks=true,
            urlcolor=blue,
            linkcolor=magenta,
            pdfborder={0 0 0}}
\urlstyle{same}  % don't use monospace font for urls
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\setcounter{secnumdepth}{0}
% Pandoc toggle for numbering sections (defaults to be off)
\setcounter{secnumdepth}{0}
% Pandoc header



\begin{document}
\begin{frontmatter}

  \title{rgbif: a package for working with species occurrence data in R}
    \author[cstar]{Scott Chamberlain\corref{c1}}
   \ead{scott(at)ropensci.org} 
   \cortext[c1]{Corresponding author}
      \address[cstar]{University of California, Berkeley, CA, USA}    
  
  \begin{abstract}
  \begin{enumerate}
  \def\labelenumi{\arabic{enumi}.}
  \item
    xxx
  \item
    xxx
  \item
    xxx
  \item
    xxxx
  \end{enumerate}
  \end{abstract}
  
 \end{frontmatter}


\section{Introduction}\label{introduction}

Perhaps the most fundamental element in many fields of ecology is the
inividual. How many individuals of each species in a given location
forms the basis for many sub-fields of ecology and evolution. Some
research questions necessitate collecting new data, while others can
easily take advantage of existing data. In fact, some ecology fields are
built largely on existing data, e.g., macro-ecology (Brown 1995; Beck
\emph{et al.} 2012).

Data on individuals, including which species, and where they're found,
can be used for a large number of research questions. In addition, the
pool of questions we can answer becomes much larger with more and better
data. In addition to wide utility, this data is important for
conservation. Biodiversity loss is one of the greatest challenges of our
time (Pimm \emph{et al.} 2014). Some have called this the sixth great
mass extinction (Ceballos \emph{et al.} 2015). Given this challenge
there is a great need for data on specimen records, whether collected
from live sightings in the field or specimens in museums.

There are many online services that collect and maintain specimen
records. However, Global Biodiversity Information Facility (hereafter,
GBIF, \url{http://www.gbif.org/}) is the largest collection of
biodiversity records globally, currently with 580 million records, 1.6
million taxa, 15,000 datasets from 770 publishers (figures collected on
2015-10-04). Many large biodiversity warehouses such as iNaturalist,
VertNet, and USGS's BISON all feed into GBIF.

Herein, we describe a library (rgbif (Chamberlain \emph{et al.})) for
working with GBIF data in the R programming environment (R Core Team
2014). R is an extremely widely used language in academia, and in
non-profit and private sectors. Importantly, R makes it easy to do all
of the steps of the research process, including data management, data
manipulation and cleaning, statistics, and vizualization. Thus, an R
client for getting GBIF data is a powerful tool for reproducible
research.

\section{The rgbif package}\label{the-rgbif-package}

The \texttt{rgbif} package is completely written in R, uses an
\href{http://choosealicense.com/licenses/mit/}{MIT license} to maximize
use everywhere. \texttt{rgbif} is developed publicly on GitHub at
\href{https://github.com/ropensci/rgbif}{\url{https://github.com/ropensci/rgbif}},
where development versions of the package can be installed, and bugs and
feature requests reported. Stable versions of \texttt{rgbif} can be
installed from
\href{https://cran.rstudio.com/web/packages/rgbif/}{CRAN}, the
distribution network for R packages. \texttt{rgbif} is part of the
rOpenSci project, a developer network making R software to facilitate
reproducible research.

\subsection{Package interface}\label{package-interface}

\texttt{rgbif} is designed following the
\href{http://www.gbif.org/developer/summary}{GBIF Application
Programming Interface}, or API. The GBIF API has four major components:
registry, species names, occurrence data, and maps. We ignore maps in
\texttt{rgbif} as it is concerned with generating maps for web
applications. \texttt{rgbif} has a suite of functions dealing with each
of registry, species names, and occurrence data - we'll go through each
in turn describing design and example usage.

\subsection{Registry}\label{registry}

The GBIF reqistry API services are spread across four sets of functions:

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  Datasets
\item
  Installations
\item
  Networks
\item
  Nodes
\item
  Organizations
\end{itemize}

\subsubsection{Datasets}\label{datasets}

Search for datasets

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{res <-}\StringTok{ }\KeywordTok{dataset_search}\NormalTok{(}\DataTypeTok{query =} \StringTok{"oregon"}\NormalTok{)}
\NormalTok{res$data$datasetTitle[}\DecValTok{1}\NormalTok{:}\DecValTok{10}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 [1] "SDNHM Birds Collection"                                                
 [2] "CM Birds Collection"                                                   
 [3] "condoncollection"                                                      
 [4] "Taxonomy in Flux Checklist"                                            
 [5] "Wool carder bees of the genus Anthidium in the Western Hemisphere"     
 [6] "Bryophyte Collection - University of Washington Herbarium (WTU)"       
 [7] "University of British Columbia Herbarium (UBC) - Bryophytes Collection"
 [8] "UWFC Ichthyology Collection"                                           
 [9] "Lichen Collection - University of Washington Herbarium (WTU)"          
[10] "UWBM Mammalogy Collection"                                             
\end{verbatim}

Get dataset metrics

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{res <-}\StringTok{ }\KeywordTok{dataset_metrics}\NormalTok{(}\DataTypeTok{uuid=}\StringTok{'66dd0960-2d7d-46ee-a491-87b9adcfe7b1'}\NormalTok{)}
\NormalTok{df <-}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{rank =} \KeywordTok{names}\NormalTok{(res$countByRank),}
                 \DataTypeTok{count =} \KeywordTok{unname}\NormalTok{(}\KeywordTok{unlist}\NormalTok{(res$countByRank)))}
\NormalTok{knitr::}\KeywordTok{kable}\NormalTok{(df)}
\end{Highlighting}
\end{Shaded}

\begin{longtable}[c]{@{}lr@{}}
\toprule
rank & count\tabularnewline
\midrule
\endhead
SPECIES & 52452\tabularnewline
GENUS & 12930\tabularnewline
VARIETY & 4806\tabularnewline
SUBSPECIES & 4440\tabularnewline
SERIES & 1079\tabularnewline
TRIBE & 844\tabularnewline
FAMILY & 509\tabularnewline
SUBTRIBE & 327\tabularnewline
SUBFAMILY & 303\tabularnewline
SUBGENUS & 241\tabularnewline
FORM & 239\tabularnewline
SECTION & 82\tabularnewline
SUBVARIETY & 4\tabularnewline
KINGDOM & 1\tabularnewline
\bottomrule
\end{longtable}

\subsubsection{Networks, nodes, and
installations}\label{networks-nodes-and-installations}

Here, we search for the first give GBIF networks, returning just the key
and title fields.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{networks}\NormalTok{(}\DataTypeTok{limit=}\DecValTok{10}\NormalTok{)$data$title}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 [1] "GBIF Backbone Sources"                                      
 [2] "Canadensys"                                                 
 [3] "Southwest Collections of Arthropods Network (SCAN)"         
 [4] "VertNet"                                                    
 [5] "Dryad"                                                      
 [6] "GBIF Network"                                               
 [7] "The Knowledge Network for Biocomplexity (KNB) "             
 [8] "Online Zoological Collections of Australian Museums (OZCAM)"
 [9] "Catalogue of Life"                                          
[10] "Ocean Biogeographic Information System (OBIS)"              
\end{verbatim}

\subsection{Species}\label{species}

\subsection{Occurrences}\label{occurrences}

GBIF provides two ways to get occurrence data: through the
\texttt{/occurrence/search} route (see \texttt{occ\_search}), or via the
\texttt{/occurrence/download} route (many functions, see below).
\texttt{occ\_search()} is the main funtion for the search route, and is
more appropriate for smaller data, while \texttt{occ\_download*()}
functions are more appropriate for larger data requests.

Large is of course a subjective term. When you hit a ``large dataset''
will depend primarily on the size of the your data request. GBIF imposes
for any given search a limit of 200,000 records in the search service,
after which point you can't download any more records for that search.
However, you can download more records for different searches.

We think the search service is still quite useful for many people even
given the 200,000 limit. For those that need more data, we have created
a similar interface in the \texttt{download\_*()} functions, that should
be easy to use. Users should take note that using the download service
has a few extra steps to get data into R, but is straight-forward.

\subsubsection{Download API}\label{download-api}

The download API syntax is similar to the occurrence search API in that
the same parameters are used, but the way in which the query is defined
is different. For example, in the download API you can do greater than
searches, whereas you can not do that in the occurrence search API.
Thus, we can't make the query interace exactly the same for both search
and download functions.

Using the download service can be as few as three steps.

Request data download given a query. Here, we xxxx

\begin{Shaded}
\begin{Highlighting}[]
\StringTok{"xxx"}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "xxx"
\end{verbatim}

You can check on when the download is ready using the functions
\texttt{occ\_download\_list()} and \texttt{occ\_download\_meta()}. When
it's ready use \texttt{occ\_download\_get()} to download the dataset to
your computer.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(res <-}\StringTok{ }\KeywordTok{occ_download_get}\NormalTok{(}\StringTok{"0000066-140928181241064"}\NormalTok{, }\DataTypeTok{overwrite =} \OtherTok{TRUE}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
<<gbif downloaded get>>
  Path: ./0000066-140928181241064.zip
  File size: 0.14 MB
\end{verbatim}

What's printed out above is a very brief summary of what was downloaded,
the path to the file, and its size (in human readable form).

Next, read the data in to R using the function
\texttt{occ\_download\_import()}.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(}\StringTok{"dplyr"}\NormalTok{)}
\NormalTok{dat <-}\StringTok{ }\KeywordTok{occ_download_import}\NormalTok{(res)}
\NormalTok{dat %>%}
\StringTok{  }\KeywordTok{select}\NormalTok{(gbifID, decimalLatitude, decimalLongitude)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
      gbifID decimalLatitude decimalLongitude
1  657590544              NA               NA
2  657679551              NA               NA
3  657791316        37.70805        -118.4162
4  658180562              NA               NA
5  441881672              NA               NA
6  911596181              NA               NA
7   56454601              NA               NA
8  657848913              NA               NA
9  658187373              NA               NA
10 658279212        38.95917        -106.9892
..       ...             ...              ...
\end{verbatim}

\subsubsection{Search API}\label{search-api}

The search API is very similar to the download API, but is meant for
smaller data acquisition jobs.

\section{Conclusions and future
directions}\label{conclusions-and-future-directions}

\subsection{Acknowledgements}\label{acknowledgements}

This project was supported in part by the Alfred P Sloan Foundation
(Grant 2013-6-22).

\subsection{Data Accessibility}\label{data-accessibility}

All software, scripts and data used in this paper can be found in the
permanent data archive Zenodo under the digital object identifier (DOI).
This DOI corresponds to a snapshot of the GitHub repository at
\href{https://github.com/sckott/msrgbif}{github.com/sckott/msrgbif}.

\section*{References}\label{references}
\addcontentsline{toc}{section}{References}

Beck, J., Ballesteros-Mejia, L., Buchmann, C.M., Dengler, J., Fritz,
S.A., Gruber, B., Hof, C., Jansen, F., Knapp, S., Kreft, H., Schneider,
A.-K., Winter, M. \& Dormann, C.F. (2012). Whats on the horizon for
macroecology? \emph{Ecography}, \textbf{35}, 673--683. Retrieved from
\url{http://dx.doi.org/10.1111/j.1600-0587.2012.07364.x}

Brown, J.H. (1995). \emph{Macroecology}. University of Chicago Press.

Ceballos, G., Ehrlich, P.R., Barnosky, A.D., Garcia, A., Pringle, R.M.
\& Palmer, T.M. (2015). Accelerated modern human-induced species losses:
Entering the sixth mass extinction. \emph{Science Advances}, \textbf{1},
e1400253--e1400253. Retrieved from
\url{http://dx.doi.org/10.1126/sciadv.1400253}

Chamberlain, S., Ram, K., Barve, V. \& Mcglinn, D. \emph{Rgbif:
Interface to the global 'biodiversity' information facility 'aPI'}.
Retrieved from \url{https://github.com/ropensci/rgbif}

Pimm, S.L., Jenkins, C.N., Abell, R., Brooks, T.M., Gittleman, J.L.,
Joppa, L.N., Raven, P.H., Roberts, C.M. \& Sexton, J.O. (2014). The
biodiversity of species and their rates of extinction, distribution, and
protection. \emph{Science}, \textbf{344}, 1246752--1246752. Retrieved
from \url{http://dx.doi.org/10.1126/science.1246752}

R Core Team. (2014). \emph{R: A language and environment for statistical
computing}. R Foundation for Statistical Computing, Vienna, Austria.
Retrieved from \url{http://www.R-project.org/}

\end{document}


